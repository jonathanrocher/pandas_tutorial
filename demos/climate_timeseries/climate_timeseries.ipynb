{
 "metadata": {
  "name": "",
  "signature": "sha256:0c0c66b13d71cb0183b08879efb235a2f3021722aac41b0d0c7aa0b3264d053a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Climate data exploration: a journey through Pandas"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Welcome to a demo of Python's data analysis package called `Pandas`. Our goal is to learn about Data Analysis and transformation using Pandas while exploring datasets used to analyze climate change. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "The story"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The global goal of this demo is to provide the tools to be able to try and reproduce some of the analysis done in the IPCC global climate reports published in the last decade (see for example https://www.ipcc.ch/pdf/assessment-report/ar5/syr/SYR_AR5_FINAL_full.pdf). \n",
      "\n",
      "We are first going to load a few datasets containing information about global temperature, global and local sea level infomation, and global concentration of greenhouse gases like CO2, to see if there are correlations and how the trends are likely to evolve. For all these datasets, we will download them, visualize them, clean them, search through them, merge them, resample them, transform them and summarize them."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the process, we will learn about:\n",
      "    1. Loading data\n",
      "    2. Pandas datastructures\n",
      "    3. Cleaning and formatting data\n",
      "    3. Basic visualization\n",
      "    4. Accessing data\n",
      "    5. Working with dates and times\n",
      "    6. Transforming datasets\n",
      "    7. Statistical analysis\n",
      "    8. Data agregation and summarization\n",
      "    9. Correlations and regressions\n",
      "    10. Predictions from auto regression models"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Some initial setup"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import pandas as pd\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from pandas import set_option\n",
      "set_option(\"display.max_rows\", 20)\n",
      "\n",
      "LARGE_FIGSIZE = (12, 8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Change this cell to the demo location on YOUR machine\n",
      "%cd ~/Projects/SciPy2015_pandas_tutorial/demos/climate_timeseries/\n",
      "%ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Loading data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "More details, see http://pandas.pydata.org/pandas-docs/stable/io.html"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To find all reading functions in pandas, ask ipython's tab completion:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#pd.read_<TAB>"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.read_table?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "From a local text file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Lets' first load some data \n",
      "# This file doesn't have any headers, so we need to provide them:\n",
      "filename = \"data/temperatures/annual.land_ocean.90S.90N.df_1901-2000mean.dat\"\n",
      "full_globe_temp = pd.read_table(filename)\n",
      "full_globe_temp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# There is only 1 column! Let's try again stating that values are separated by \n",
      "# any number of spaces:\n",
      "full_globe_temp = pd.read_table(filename, sep=\"\\s+\")\n",
      "full_globe_temp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# There are columns by the column names are 1880 and -0.1591!\n",
      "full_globe_temp = pd.read_table(filename, sep=\"\\s+\", names=[\"year\", \"mean temp\"])\n",
      "full_globe_temp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Since we only have 2 columns, let's try using the index_col option:\n",
      "full_globe_temp = pd.read_table(filename, sep=\"\\s+\", names=[\"year\", \"mean temp\"], \n",
      "                                index_col=0)\n",
      "full_globe_temp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Last step: the index is made of dates. Let's make that explicit:\n",
      "full_globe_temp = pd.read_table(filename, sep=\"\\s+\", names=[\"year\", \"mean temp\"], \n",
      "                                index_col=0, parse_dates=True)\n",
      "full_globe_temp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "From a chunked file"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "NASA's GISS dataset is written in chunks: look at it in `data/temperatures/GLB.Ts+dSST.txt`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "giss_temp = pd.read_table(\"data/temperatures/GLB.Ts+dSST.txt\", sep=\"\\s+\", skiprows=7, \n",
      "                          skip_footer=11, engine=\"python\")\n",
      "giss_temp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**EXERCISE:** Load some readings of CO2 concentrations in the atmosphere from the `greenhouse_gaz/co2_mm_global.txt` data file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "From a remote text file"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's load some alternate temperature data that isn't local but online (http://cdiac.ornl.gov/ftp/trends/temp/lugina/90N-60S.dat). That is done by replacing the filepath by a URL."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Another dataset, broken by month is offered on ORNL's website:\n",
      "# Local backup: data/temperatures/90N-60S.dat.txt\n",
      "url = \"http://cdiac.ornl.gov/ftp/trends/temp/lugina/90N-60S.dat\"\n",
      "pd.read_table(url, sep=\"\\s+\", skiprows=24, skipfooter=1, engine=\"python\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**QUIZ:** What happens if you remove the `skiprows`? `skipfooter`? `engine`?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The university of colorado posts updated timeseries for mean sea level globably, per \n",
      "# hemisphere, or even per ocean, sea, ... Let's download the global one, and the ones for\n",
      "# the northern and southern hemisphere:\n",
      "# Local backup: data/sea_levels/sl_nh.txt\n",
      "northern_sea_level = pd.read_table(\"http://sealevel.colorado.edu/files/current/sl_nh.txt\", \n",
      "                                   sep=\"\\s+\")\n",
      "northern_sea_level"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Local backup: data/sea_levels/sl_sh.txt\n",
      "southern_sea_level = pd.read_table(\"http://sealevel.colorado.edu/files/current/sl_sh.txt\", \n",
      "                                   sep=\"\\s+\")\n",
      "southern_sea_level"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The 2015 version of the global dataset:\n",
      "# Local backup: data/sea_levels/sl_ns_global.txt\n",
      "url = \"http://sealevel.colorado.edu/files/2015_rel2/sl_ns_global.txt\"\n",
      "global_sea_level = pd.read_table(url, sep=\"\\s+\")\n",
      "global_sea_level"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "From a local or remote HTML file"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To be able to grab more local data about mean sea levels, we can download and extract data about mean sea level stations around the world from the PSMSL:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Local backup in data/sea_levels/Obtaining Tide Gauge Data.html\n",
      "table_list = pd.read_html(\"http://www.psmsl.org/data/obtaining/\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# there is 1 table on that page which contains metadata about the stations where \n",
      "# sea levels are recorded\n",
      "local_sea_level_stations = table_list[-1]\n",
      "local_sea_level_stations"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That table can be used to search for a station in a region of the world we choose, extract an ID for it and download the corresponding time series with the URL http://www.psmsl.org/data/obtaining/met.monthly.data/< ID >.metdata"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Pandas DataStructures"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For more details, see http://pandas.pydata.org/pandas-docs/stable/dsintro.html"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "DataFrame, the pandas 2D structure"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Type of the object?\n",
      "type(giss_temp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "giss_temp.index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "giss_temp.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Internal nature of the object\n",
      "print(giss_temp.shape)\n",
      "print(giss_temp.dtypes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# A lot of information at once including memory usage:\n",
      "giss_temp.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Series, the pandas 1D structure"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A series can be constructed with the `pd.Series` constructor (passing a list or array of values) or from a `DataFrame`, by extracting one of its columns."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Do we already have a series for the full_globe_temp?\n",
      "type(full_globe_temp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Since there is only one column of values, we can make this a Series without \n",
      "# loosing information:\n",
      "full_globe_temp = full_globe_temp[\"mean temp\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Core information:\n",
      "print(type(full_globe_temp))\n",
      "print(full_globe_temp.dtype)\n",
      "print(full_globe_temp.shape)\n",
      "print(full_globe_temp.nbytes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "full_globe_temp.index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's make a new frame from the 3 sea level datasets we downloaded:\n",
      "# Are they aligned?\n",
      "southern_sea_level.year == northern_sea_level.year"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# So, are they aligned?\n",
      "np.all(southern_sea_level.year == northern_sea_level.year)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean_sea_level = pd.DataFrame({\"northern_hem\": northern_sea_level[\"msl_ib(mm)\"], \n",
      "                               \"southern_hem\": southern_sea_level[\"msl_ib(mm)\"], \n",
      "                               \"mean_global\": global_sea_level[\"msl_ib_ns(mm)\"], \n",
      "                               \"date\": northern_sea_level.year})\n",
      "mean_sea_level"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "NumPy arrays as backend of Pandas"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is always possible to fall back to a good old NumPy to pass on to scientific libraries that need them: SciPy, scikit-learn, ..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "full_globe_temp.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(full_globe_temp.values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Cleaning and formatting data"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Rename columns"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The columns of the local_sea_level_stations aren't clean: they contain spaces and dots.\n",
      "local_sea_level_stations.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's clean them up a bit:\n",
      "local_sea_level_stations.columns = [name.strip().replace(\".\", \"\") \n",
      "                                    for name in local_sea_level_stations.columns]\n",
      "local_sea_level_stations.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Setting missing values"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "full_globe_temp == -999.000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "full_globe_temp[full_globe_temp == -999.000] = np.nan\n",
      "full_globe_temp.tail()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Choosing what is the index"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We didn't set a column number of the index of giss_temp, we can do that afterwards:\n",
      "giss_temp = giss_temp.set_index(\"Year\")\n",
      "giss_temp.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let do the same with the sea level dataset:\n",
      "mean_sea_level = mean_sea_level.set_index(\"date\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Dropping rows and columns"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 1 column is redundant with the index: \n",
      "giss_temp.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's drop it:\n",
      "giss_temp = giss_temp.drop(\"Year.1\", axis=1)\n",
      "giss_temp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We can also just select the columns we want to keep:\n",
      "giss_temp = giss_temp[[u'Jan', u'Feb', u'Mar', u'Apr', u'May', u'Jun', u'Jul', \n",
      "                       u'Aug', u'Sep', u'Oct', u'Nov', u'Dec']]\n",
      "giss_temp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's remove all these extra column names (Year  Jan ...). They all correspond to the index \"Year\"\n",
      "giss_temp = giss_temp.drop(\"Year\")\n",
      "giss_temp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's set **** to a real missing value (np.nan). This could have been \n",
      "# done in read_table with `na_values`\n",
      "giss_temp[giss_temp == \"****\"] = np.nan \n",
      "giss_temp.tail()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Changing dtype of series"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Because of the labels found in the middle of the timeseries, every column is only assuming to contain strings:\n",
      "giss_temp.dtypes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "giss_temp[\"Jan\"].astype(\"float32\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for col in giss_temp.columns:\n",
      "    giss_temp[col] = giss_temp[col].astype(np.float32)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# An index has a dtype just like any Series:\n",
      "giss_temp.index = giss_temp.index.astype(np.int32)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Removing missing values"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "full_globe_temp.dropna()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This will remove any year that has a missing value. Use how='all' to keep partial years\n",
      "giss_temp.dropna(how=\"any\").tail()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This fills them with the previous year. See also temp3.interpolate\n",
      "giss_temp.fillna(method=\"ffill\").tail()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Basic visualization"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Line plots"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "full_globe_temp.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "giss_temp.plot(figsize=LARGE_FIGSIZE)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean_sea_level.plot(subplots=True, figsize=(16, 12));"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Showing distributions information"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Distributions of mean sean level globally and per hemisphere?\n",
      "mean_sea_level.plot(kind=\"kde\", figsize=(12, 8))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Distributions of temperature in each month since 1880\n",
      "giss_temp.boxplot();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Correlations"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Is there correlations between anomalies for each month?\n",
      "from pandas.tools.plotting import scatter_matrix\n",
      "scatter_matrix(mean_sea_level, figsize=LARGE_FIGSIZE);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will confirm the correlations we think we see further down..."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Accessing data"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "In a series"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "full_globe_temp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# By default [] on a series accesses values using the index, not the location in the series\n",
      "# print(temp1[0])  # This would to fail!!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This index is non-trivial though (will talk more about these datetime objects further down):\n",
      "full_globe_temp.index.dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "first_date = full_globe_temp.index[0]\n",
      "first_date == pd.Timestamp('1880')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# By default [] on a series accesses values using the index, not the location in the series\n",
      "print(full_globe_temp[pd.Timestamp('1880')])\n",
      "# print(temp1[0])  # This would fail!!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Another more explicit way to do the same thing is to use loc\n",
      "print(full_globe_temp.loc[pd.Timestamp('1990')])\n",
      "print(full_globe_temp.iloc[0], full_globe_temp.iloc[-1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Year of the last record?\n",
      "full_globe_temp.index[-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# New records can be added:\n",
      "full_globe_temp[pd.Timestamp('2011')] = np.nan"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "In a dataframe"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# In 2D, same idea, though in a DF [] accesses columns (Series)\n",
      "giss_temp[\"Jan\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# while .loc and .iloc allow to access individual values, slices or masked selections:\n",
      "print(giss_temp.loc[1979, \"Dec\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Slicing can be done with .loc and .iloc\n",
      "print(giss_temp.loc[1979, \"Jan\":\"Jun\"])  # Note that the end point is included unlike NumPy!!!\n",
      "print(giss_temp.loc[1979, ::2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Masking can also be used in one or more dimensions. For example, another way to grab every other month for the first year:\n",
      "mask = [True, False] * 6\n",
      "print(giss_temp.iloc[0, mask])\n",
      "print(giss_temp.loc[1880, mask])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We could also add a new column like a new entry in a dictionary\n",
      "giss_temp[\"totals\"] = giss_temp.sum(axis=1)\n",
      "giss_temp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's remove this new column, we will learn to do this differently\n",
      "giss_temp = giss_temp.drop(\"totals\", axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "More complex queries rely on the same concepts. For example what are the names, and IDs of the sea level stations in the USA?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "local_sea_level_stations.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "american_stations = local_sea_level_stations[\"Country\"] == \"USA\"\n",
      "local_sea_level_stations.loc[american_stations, [\"ID\", \"Station Name\"]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Working with dates and times"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "More details at http://pandas.pydata.org/pandas-docs/stable/timeseries.html"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's work some more with full_globe_temp's index since we saw it is more special"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Its dtype is NumPy's new 'datetime64[ns]':\n",
      "full_globe_temp.index.dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The advantage of having a real datetime index is that operations can be done efficiently on it. Let's add a flag to signal if the value is before or after the great depression's black Friday:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "black_friday = pd.to_datetime('1929-10-29')\n",
      "full_globe_temp.index > black_friday"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Timestamps or periods?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Convert its index from timestamp to period: it is more meaningfull since it was measured and averaged over the year...\n",
      "full_globe_temp.index = full_globe_temp.index.to_period()\n",
      "full_globe_temp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "See also `to_timestamp` to conver back to timestamps and its `how` method to specify when inside the range to set the timestamp."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Resampling"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another thing that can be done is to resample the series, downsample or upsample. Let's see the series converted to 10 year blocks or upscale to a monthly series:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Frequencies can be specified as strings: \"us\", \"ms\", \"S\", \"T\", \"H\", \"D\", \"B\", \"W\", \"M\", \"A\", \"3min\", \"2h20\", ...\n",
      "# More aliases at http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases\n",
      "full_globe_temp.resample(\"M\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "full_globe_temp.resample(\"10A\", how=\"mean\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Generating DatetimeIndex objects"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The index for giss_temp isn't instance of datetimes so we may want to generate such DatetimeIndex objects. This can be done with `date_range` and `period_range`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Can specify a start date and a number of values desired. By default it will assume an interval of 1 day:\n",
      "pd.date_range('1/1/1880', periods=4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Can also specify a start and a stop date, as well as a frequency\n",
      "pd.date_range('1/1/1880', '1/1/2016', freq=\"A\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Note that A by default, means the end of the year. Other times in the year can be specified with \n",
      "# \"AS\" (start), \"A-JAN\" or \"A-JUN\". Even more options can be imported from pandas:\n",
      "from pandas.tseries.offsets import YearBegin\n",
      "pd.date_range('1/1/1880', '1/1/2015', freq=YearBegin())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Actually we will convert that dataset to a 1D dataset, and build a monthly index:\n",
      "giss_temp_index = pd.period_range('1/1/1880', '12/1/2015', freq=\"M\")\n",
      "giss_temp_index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Transforming datasets: apply, sort, unstack and transpose"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's first look at our `mean_sea_level` data some more. What is the range of dates and lattitude we have, the list of countries, the range of variations, ..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# What about the range of dates?\n",
      "print(local_sea_level_stations[\"Date\"].min(), local_sea_level_stations[\"Date\"].max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "local_sea_level_stations.dtypes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Apply: transforming a Series"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We don't see the range of dates because the dates are of dtype \"Object\", (usually meaning strings). Let's convert that using `apply`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "local_sea_level_stations[\"Date\"].apply(pd.to_datetime)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "local_sea_level_stations[\"Date\"] = local_sea_level_stations[\"Date\"].apply(pd.to_datetime)\n",
      "\n",
      "# Now we can really compare the dates, and therefore get a real range:\n",
      "print(local_sea_level_stations[\"Date\"].min(), local_sea_level_stations[\"Date\"].max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now that the dates can be compared properly, let's see all the stations sorted by the ones updated last, \n",
      "# and then by countries\n",
      "local_sea_level_stations.sort([\"Date\", \"Country\"], ascending=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Stack and unstack"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# stacking and unstacking allows to convert a dataframe into a series and vice-versa:\n",
      "giss_temp.unstack?\n",
      "unstacked = giss_temp.unstack()\n",
      "unstacked"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Note the nature of the result:\n",
      "type(unstacked)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The result is grouped in the wrong order since it sorts first the axis that was unstacked. Another transformation that would help us is transposing..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "giss_temp.transpose()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "giss_temp_series = giss_temp.transpose().unstack()\n",
      "giss_temp_series.name = \"Temp anomaly\"\n",
      "giss_temp_series"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "A side note: Multi-indexes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Note the nature of the resulting index:\n",
      "giss_temp_series.index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# It is an index made of 2 columns. Let's fix the fact that one of them doesn't have a name:\n",
      "giss_temp_series.index = giss_temp_series.index.set_names([\"year\", \"month\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We can now access deviations by specifying the year and month:\n",
      "giss_temp_series[1980, \"Jan\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# But the index isn't yet very good, because is it now viewed as 1 date\n",
      "giss_temp_series.plot(figsize=LARGE_FIGSIZE)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "giss_temp_series.index = giss_temp_index\n",
      "giss_temp_series.plot(figsize=LARGE_FIGSIZE)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Statistical analysis"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Descriptive statistics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's go back to the dataframe version of the GISS temperature dataset temporarily to analyze anomalies month per month"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Like most functions on a dataframe, stats function are computed column per column\n",
      "# They also ignore missing values\n",
      "monthly_averages = giss_temp.mean()\n",
      "monthly_averages"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Many descriptive stats computed at once:\n",
      "mean_sea_level.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Rolling statistics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's remove high frequency signal and extract the trend:\n",
      "full_globe_temp.plot()\n",
      "pd.rolling_mean(full_globe_temp, 10).plot(figsize=LARGE_FIGSIZE)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# To see what all can be done while rolling, \n",
      "#pd.rolling_<TAB>"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Analyzing categorical series"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's look at our sea level station dataset some more:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "local_sea_level_stations.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`.describe()` only displays information about continuous `Series`. What about categorical ones:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "local_sea_level_stations.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "local_sea_level_stations[\"Country\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "local_sea_level_stations[\"Country\"].describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# List of unique values:\n",
      "local_sea_level_stations[\"Country\"].unique()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "local_sea_level_stations[\"Country\"].value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# To save memory, we can convert it to a categorical column:\n",
      "local_sea_level_stations[\"Country\"] = local_sea_level_stations[\"Country\"].astype(\"category\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We can also create categorical series from continuous ones with the cut function:\n",
      "categorized = pd.cut(full_globe_temp, 3, labels=[\"L\", \"M\", \"H\"])\n",
      "categorized"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The advantage is that we can use labels and control the order they should be treated in (L < M < H)\n",
      "categorized.cat.categories"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**QUIZ:** How much memory did we save? What if it was categorized by with dtype `object` instead of `category`?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Data Aggregation/summarization"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "GroupBy"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's explore the sea levels split into the northern and southern hemisphere."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean_sea_level"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Groupby with pandas can be done on a column or by applying a custom function to the index. \n",
      "# If we want to group the data by year, we can build a year column into the DF:\n",
      "mean_sea_level = mean_sea_level.reset_index()\n",
      "mean_sea_level[\"year\"] = mean_sea_level[\"date\"].apply(int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean_sea_level"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sl_grouped_year = mean_sea_level.groupby(\"year\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for group_name, subdf in sl_grouped_year:\n",
      "    print(group_name)\n",
      "    print(subdf)\n",
      "    print(\"\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We could have done the same with less effort by grouping by the result of a custom function applied \n",
      "# to the index:\n",
      "# Let's reset the dataframe:\n",
      "mean_sea_level = mean_sea_level.drop([\"year\"], axis=1).set_index(\"date\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# So that we can do the groupby on the index:\n",
      "sl_grouped_year = mean_sea_level.groupby(int)\n",
      "# In addition to looping over the groupby object, we can look at its groups attribute to see \n",
      "# the labels mapped to the rows involved:\n",
      "sl_grouped_year.groups"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# How to aggregate the results of this grouping depends on what we want to see: do we want to see averaged \n",
      "# over the years?\n",
      "sl_grouped_year.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We can apply any other reduction function or even a dict of functions using aggregate:\n",
      "sl_grouped_year.aggregate({\"mean_global\": np.std})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another possibility is to transform each group separately, rather than aggregate. For example, here we group over decades and subtract to each value, the average over that decade:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sl_grouped_decade = mean_sea_level.groupby(lambda x: int(x/10.))\n",
      "sl_grouped_decade.groups.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sl_grouped_decade.transform(lambda subframe: (subframe - subframe.mean()/subframe.std()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Pivot_table"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pivot table also allows to summarize the information, allowing to convert repeating columns into axes. For example, let's say that we would like to know how many sea level stations are in various european countries. And we would like to group the answers into 2 categories: the stations that have been updated recently (after 2000) and the others. \n",
      "\n",
      "Let's first extract only entries located (roughly) in Europe."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "european_filter = ((local_sea_level_stations[\"Lat\"] > 30) & \n",
      "                   (local_sea_level_stations[\"Lat\"] < 70) & \n",
      "                   (local_sea_level_stations[\"Lon\"] > -10) & \n",
      "                   (local_sea_level_stations[\"Lon\"] < 40) \n",
      "                   )\n",
      "\n",
      "# Let's make a copy to work with a new, clean block of memory \n",
      "# (if you are interested, try and remove the copy to see the consequences further down...\n",
      "european_stations = local_sea_level_stations[european_filter].copy()\n",
      "european_stations[\"Country\"].unique()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The columns of our future table should have 2 values, whether the station was updated recently or not. Let's build a column to store that information:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "european_stations[\"Recently updated\"] = european_stations[\"Date\"] > pd.to_datetime(\"2000\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, what value will be displayed inside the table. The values should be extracted from a column, pivot_table allowing an aggregation function to be applied when more than 1 value is found for a given case. Each station should count for 1, and we could aggregate multiple stations by summing these ones:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "european_stations[\"Number of stations\"] = np.ones(len(european_stations))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "european_stations.sort(\"Country\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "station_counts = pd.pivot_table(european_stations, index=\"Country\", columns=\"Recently updated\", \n",
      "                                values=\"Number of stations\", aggfunc=np.sum)\n",
      "# Let's remove from the table the countries for which no station was found:\n",
      "station_counts.dropna(how=\"all\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**QUIZ:** Why is there still some countries with no entries?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**EXERCISE:** How many recently updated stations? Not recently updated stations? Which country has the most stations? Which country has the most recently updated stations?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**EXERCISE:** How would we build the same dataframe with a `groupby` operation?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Correlations and regressions"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Correlation coefficients"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Both Series and dataframes have a `corr` method to compute the correlation coefficient between series:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's see what how the various sea levels are correlated with each other:\n",
      "mean_sea_level[\"northern_hem\"].corr(mean_sea_level[\"southern_hem\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# If series are already grouped into a DataFrame, computing all correlation coeff is trivial:\n",
      "mean_sea_level.corr()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note: by default, the method used is the `Pearson` correlation coefficient (https://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient). Other methods are available (`kendall`, `spearman` using the `method` kwarg)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Visualize the correlation matrix\n",
      "plt.imshow(mean_sea_level.corr(), interpolation=\"nearest\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.yticks?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's make it a little better to confirm that learning about global sea level cannot be done from just \n",
      "# looking at stations in the northern hemisphere:\n",
      "plt.imshow(mean_sea_level.corr(), interpolation=\"nearest\")\n",
      "plt.xticks(np.arange(3), mean_sea_level.corr().columns)\n",
      "plt.yticks(np.arange(3), mean_sea_level.corr().index)\n",
      "plt.colorbar()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "OLS"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are 2 objects constructors inside Pandas and inside `statsmodels`. There has been talks about merging the 2 into SM, but that hasn't happened yet. OLS in statsmodels allows more complex formulas:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import statsmodels.formula.api as sm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sm_model = sm.ols(formula=\"mean_global ~ northern_hem + southern_hem\", data=mean_sea_level).fit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sm_model.params"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print type(sm_model.params)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sm_model.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean_sea_level[\"mean_global\"].plot()\n",
      "sm_model.fittedvalues.plot(label=\"OLS prediction\")\n",
      "plt.legend(loc=\"upper left\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OLS in pandas requires to pass a `y` series and an `x` series to do a fit of the form `y ~ x`. But the formula can be more complex by providing a `DataFrame` for x and reproduce a formula of the form `y ~ x1 + x2`. \n",
      "\n",
      "Also, OLS in pandas allows to do rolling and expanding OLS:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas.stats.api import ols as pdols"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Same fit as above:\n",
      "pd_model = pdols(y=mean_sea_level[\"mean_global\"], x=mean_sea_level[[\"northern_hem\", \"southern_hem\"]])\n",
      "pd_model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(figsize=LARGE_FIGSIZE)\n",
      "mean_sea_level[\"mean_global\"].plot()\n",
      "pd_model.predict().plot(label=\"OLS prediction\")\n",
      "plt.legend(loc=\"upper left\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "An interlude: data Alignment and merge"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Converting the floating point date to a timestamp"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we would like to look for correlations between our monthly temperatures and the sea levels we have. For this to be possible, some data alignment must be done since the time scales are very different for the 2 datasets. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean_sea_level[\"mean_global\"].index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "giss_temp_series.index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DAYS_PER_YEAR = {}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import calendar\n",
      "# Let's first convert the floating point dates in the sea level to timestamps:\n",
      "def floating_year_to_timestamp(float_date):\n",
      "    \"\"\" Convert a date as a floating point year number to a pandas timestamp object.\n",
      "    \"\"\"\n",
      "    year = int(float_date)\n",
      "    days_per_year = 366 if calendar.isleap(year) else 365\n",
      "    remainder = float_date - year\n",
      "    daynum = 1 + remainder * (days_per_year - 1)\n",
      "    daynum = int(round(daynum))\n",
      "    # Convert day number to month and day\n",
      "    day = daynum\n",
      "    month = 1\n",
      "    while month < 13:\n",
      "        month_days = calendar.monthrange(year, month)[1]\n",
      "        if day <= month_days:\n",
      "            return pd.Timestamp(str(year)+\"/\"+str(month)+\"/\"+str(day))\n",
      "        day -= month_days\n",
      "        month += 1\n",
      "    raise ValueError('{} does not have {} days'.format(year, daynum))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "floating_year_to_timestamp(1996.0), floating_year_to_timestamp(1996.5), floating_year_to_timestamp(1996.9999)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dt_index = pd.Series(mean_sea_level[\"mean_global\"].index).apply(floating_year_to_timestamp)\n",
      "dt_index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean_sea_level = mean_sea_level.reset_index(drop=True)\n",
      "mean_sea_level.index = dt_index\n",
      "mean_sea_level"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, how to align the 2 series? Is this one sampled regularly so that the month temperatures can be upscaled to that frequency?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Computing the difference between successive values"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What is the frequency of that new index?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dt_index.dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# What is the frequency of the new index? The numpy way to compute differences between all values doesn't work:\n",
      "dt_index[1:] - dt_index[:-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Note: the result of a difference of timestamps is a series of timedeltas\n",
      "(dt_index[1:] - dt_index[:-1]).dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**IMPORTANT Note:** The above failure is due to the fact that operations between series automatically align them based on their index."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# There is a method for shifting values up/down the index:\n",
      "dt_index.shift()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# So the distances can be computed with \n",
      "dt_index - dt_index.shift()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Not constant reads apparently. Let's downscale the frequency of the sea levels \n",
      "# to monthly, like the temperature reads we have:\n",
      "monthly_mean_sea_level = mean_sea_level.resample(\"MS\").to_period()\n",
      "monthly_mean_sea_level"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "monthly_mean_sea_level[\"mean_global\"].align(giss_temp_series)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "giss_temp_series.align?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now that the series are using the same type and frequency of indexes, to align them is trivial:\n",
      "monthly_mean_sea_level[\"mean_global\"].align(giss_temp_series, join='inner')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aligned_sl, aligned_temp = monthly_mean_sea_level[\"mean_global\"].align(giss_temp_series, join='inner')\n",
      "aligned_df = pd.DataFrame({\"mean_sea_level\": aligned_sl, \"mean_global_temp\": aligned_temp})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The alignment can even be done on an entire dataframe:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "monthly_mean_sea_level.align(giss_temp_series, axis=0, join='inner')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aligned_sea_levels, aligned_temp = monthly_mean_sea_level.align(giss_temp_series, axis=0, join='inner')\n",
      "aligned_monthly_data = aligned_sea_levels.copy()\n",
      "aligned_monthly_data[\"global_temp\"] = aligned_temp\n",
      "aligned_monthly_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Correlations between sea levels and temperatures"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aligned_monthly_data.plot(figsize=LARGE_FIGSIZE)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aligned_monthly_data.corr()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = sm.ols(\"southern_hem ~ global_temp\", data=aligned_monthly_data).fit()\n",
      "model.rsquared"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What if we had done the analysis yearly instead of monthly to remove seasonal variations?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aligned_yearly_data = aligned_monthly_data.resample(\"A\")\n",
      "aligned_yearly_data.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aligned_yearly_data.corr()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = sm.ols(\"southern_hem ~ global_temp\", data=aligned_yearly_data).fit()\n",
      "model.rsquared"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Predictions from auto regression models"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "An auto-regresssive model fits existing data and build a (potentially predictive) model of the data fitted. We use the timeseries analysis (`tsa`) submodule of `statsmodels` to make out-of-sample predictions for the upcoming decades:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import statsmodels as sm\n",
      "# Let's remove seasonal variations by resampling annually\n",
      "data = giss_temp_series.resample(\"A\").to_timestamp()\n",
      "ar_model = sm.tsa.ar_model.AR(data, freq='A')\n",
      "ar_res = ar_model.fit(maxlag=60, disp=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(figsize=LARGE_FIGSIZE)\n",
      "pred = ar_res.predict(start='1950-1-1', end='2070')\n",
      "data.plot(style='k', label=\"Historical Data\")\n",
      "pred.plot(style='r', label=\"Predicted Data\")\n",
      "plt.ylabel(\"Temperature variation (0.01 degC)\")\n",
      "plt.legend()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**EXERCISE:** Make another auto-regression on the sea level of the Atlantic ocean to estimate how much New York is going to flood in the coming century. You can find the historical sea levels of the Atlantic ocean at http://sealevel.colorado.edu/files/current/sl_Atlantic_Ocean.txt or data/sea_levels/sl_Atlantic_Ocean.txt."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}